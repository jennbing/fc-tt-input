function [net, info] = fcn_mnist_autonn_tt_input(varargin)
% CNN_MNIST_AUTONN_TT_INPUT  Train on MNIST data stored / computed
% in TT format.

% Fix the random seed.
rng(0);

opts.expDir = fullfile('data','mnist-baseline') ;
[opts, varargin] = vl_argparse(opts, varargin) ;

opts.dataDir = fullfile('data','mnist') ;
opts.imdbPath = fullfile(opts.expDir, 'imdb.mat');
opts.train.batchSize = 100;
opts.train.numEpochs = 100 ;
opts.train.continue = true ;
opts.train.gpus = [] ;
opts.train.learningRate = logspace(-2, -5, 45);
opts.train.expDir = opts.expDir ;
opts = vl_argparse(opts, varargin) ;

% --------------------------------------------------------------------
%                                                         Prepare data
% --------------------------------------------------------------------

if exist(opts.imdbPath, 'file')
  imdb = load(opts.imdbPath) ;
else
  imdb = getMnistImdb(opts) ;
  mkdir(opts.expDir) ;
  save(opts.imdbPath, '-struct', 'imdb') ;
end

  images = Input('gpu', true) ;
  labels = Input() ;

    inputModeSize = [4, 7, 1, 7, 4] ;
    secondModeSize = [5, 5, 5, 5, 5] ;
    ranks = [1, 2, 2, 2, 2, 1] ;
    
    W = tt_rand(secondModeSize.*inputModeSize, length(secondModeSize), ranks, []) ;
    W = tt_matrix(W, secondModeSize, inputModeSize) ;
    W.core = single(W.core) ;  
    
    x = vl_nntt_forward(images, 'W', W, ...
                           'weights', {W.core, zeros(1,1,prod(secondModeSize),'single')}, ...
                           'learningRate', [1, 2], ...
                           'weightDecay', [1, 0], ...
                           'outHeight', 1, ...
                           'outWidth', 1, ...
                           'outChannels', prod(secondModeSize)) ;
    x = vl_nnrelu(x) ;
    x = vl_nnconv(x, ... % 'weights', {{0.1*randn(1,1,prod(secondModeSize),10, 'single'), zeros(1, 10, 'single')}}, ...
                     'size', [1,1,prod(secondModeSize),10], ...
                     'learningRate', [1, 2], ...
                     'weightDecay', [1, 0], ...
                     'stride', 1, ...
                     'pad', 0) ;  
  
%   % diagnose outputs of conv layers
%   Layer.setDiagnostics(x.find(@vl_nnconv), true) ;

  % diagnose all Params associated with conv layers (1 depth up from them)
  convs = x.find(@vl_nnconv) ;
  convParams = cellfun(@(x) x.find('Param', 'depth', 1), convs, 'Uniform', false) ;
  Layer.setDiagnostics(convParams, true) ;
  
  objective = vl_nnloss(x, labels, 'loss', 'softmaxlog') ;
  error = vl_nnloss(x, labels, 'loss', 'classerror') ;

  Layer.workspaceNames() ;  % assign layer names based on workspace variables (e.g. 'images', 'objective')
  net = Net(objective, error) ;  % compile network
  
% --------------------------------------------------------------------
%                                                                Train
% --------------------------------------------------------------------

[net, info] = cnn_train_autonn(net, imdb, @getBatch, ...
  opts.train, 'val', find(imdb.images.set == 3)) ;

% --------------------------------------------------------------------
function [inputs] = getBatch(imdb, batch)
% --------------------------------------------------------------------

%{
% Plot images before and after compression
images = imdb.images.data(:,batch,:) ;
labels = imdb.images.labels(1,batch) ;
images1 = tt_tensor(images, 0, [4 7 length(batch) 7 4]);
images1 = round(images1,1e-1,5);
images1 = reshape(full(images1),28,[],28);
figure();
for i=1:10
    subplot(2,10,i)
    for j=1:length(batch)
        if labels(j)==i
            imshow(reshape(images(:,j,:),28,28),[0 255]);
            subplot(2,10,i+10)
            imshow(reshape(images1(:,j,:),28,28),[0 255]);
            break;
        end
    end
end
saveas(gcf,'im_input.png');
%}

images = imdb.images.data(:,batch,:) ;
images = tt_tensor(images, 0, [4 7 length(batch) 7 4]);
images = round(images,0,5);
images = tt_matrix(images,[4 7 1 7 4],[1 1 length(batch) 1 1]);
labels = imdb.images.labels(1,batch) ;
inputs = {'images', images, 'labels', labels} ;

% --------------------------------------------------------------------
function imdb = getMnistImdb(opts)
% --------------------------------------------------------------------
% Prepare the imdb structure, returns image data with images of size 32 x 32
% and the mean image subtracted.
files = {'train-images-idx3-ubyte', ...
         'train-labels-idx1-ubyte', ...
         't10k-images-idx3-ubyte', ...
         't10k-labels-idx1-ubyte'} ;

if ~exist(opts.dataDir, 'dir')
  mkdir(opts.dataDir) ;
end

for i=1:4
  if ~exist(fullfile(opts.dataDir, files{i}), 'file')
    url = sprintf('http://yann.lecun.com/exdb/mnist/%s.gz',files{i}) ;
    fprintf('downloading %s\n', url) ;
    gunzip(url, opts.dataDir) ;
  end
end

f=fopen(fullfile(opts.dataDir, 'train-images-idx3-ubyte'),'r') ;
x1=fread(f,inf,'uint8');
fclose(f) ;
x1=permute(reshape(x1(17:end),28,28,60e3),[2 3 1]) ;

f=fopen(fullfile(opts.dataDir, 't10k-images-idx3-ubyte'),'r') ;
x2=fread(f,inf,'uint8');
fclose(f) ;
x2=permute(reshape(x2(17:end),28,28,10e3),[2 3 1]) ;

f=fopen(fullfile(opts.dataDir, 'train-labels-idx1-ubyte'),'r') ;
y1=fread(f,inf,'uint8');
fclose(f) ;
y1=double(y1(9:end)')+1 ;

f=fopen(fullfile(opts.dataDir, 't10k-labels-idx1-ubyte'),'r') ;
y2=fread(f,inf,'uint8');
fclose(f) ;
y2=double(y2(9:end)')+1 ;

set = [ones(1,numel(y1)) 3*ones(1,numel(y2))] ;
dataSmall = single(reshape(cat(2, x1, x2),28,[],28)) ;
% Fill the image with zeros on the border to resize it to 32 x 32.
%data = zeros(32, size(dataSmall, 2), 32) ;
%data(3:30, :, 3:30) = dataSmall ;
dataMean = mean(dataSmall(:,set == 1,:), 2) ;
data = bsxfun(@minus, dataSmall, dataMean) ;

imdb.images.data = data ;
imdb.images.data_mean = dataMean ;
imdb.images.labels = cat(2, y1, y2) ;
imdb.images.set = set ;
imdb.meta.sets = {'train', 'val', 'test'} ;
imdb.meta.classes = arrayfun(@(x)sprintf('%d',x),0:9,'uniformoutput',false) ;
